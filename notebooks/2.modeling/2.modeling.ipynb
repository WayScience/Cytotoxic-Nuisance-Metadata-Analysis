{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Modeling \n",
    "\n",
    "In this notebook, we focus on developing and training a Multi-class logistic regression model, employing Randomized Cross-Validation (CV) for hyperparameter tuning to address our classification task. The dataset is split into an 79% training set and a 20% testing set. To evaluate the performance of our model during training, we used performance evaluation metrics such as precision, recall, and F1 scores. Additionally, we extend our evaluation by testing our model on a holdout dataset, which includes plate, treatment, and well information, providing a comprehensive assessment of its real-world performance.\n",
    "\n",
    "In this notebook, we will train four models:\n",
    "\n",
    "- A model using feature-selected cell injury profiles\n",
    "- A model using shuffled feature-selected cell injury profiles\n",
    "- A model using JUMP-aligned feature-selected cell injury profiles\n",
    "- A model using shuffled JUMP-aligned feature-selected cell injury profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import local modules\n",
    "sys.path.append(\"../../\")\n",
    "from src.utils import (\n",
    "    train_multiclass,\n",
    "    shuffle_features,\n",
    "    load_json_file,\n",
    "    generate_confusion_matrix_tl,\n",
    "    evaluate_model_performance,\n",
    "    get_coeff_scores,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting random seeds variables\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting directory paths\n",
    "results_dir = pathlib.Path(\"../../results\").resolve(strict=True)\n",
    "feature_dir = (results_dir / \"0.feature_selection/\").resolve(strict=True)\n",
    "data_splits_dir = (results_dir / \"1.data_splits\").resolve(strict=True)\n",
    "\n",
    "# setting test and train data paths\n",
    "aligned_X_train_path = (data_splits_dir / \"aligned_X_train.csv.gz\").resolve(strict=True)\n",
    "aligned_X_test_path = (data_splits_dir / \"aligned_X_test.csv.gz\").resolve(strict=True)\n",
    "aligned_y_train_path = (data_splits_dir / \"aligned_y_train.csv.gz\").resolve(strict=True)\n",
    "aligned_y_test_path = (data_splits_dir / \"aligned_y_test.csv.gz\").resolve(strict=True)\n",
    "\n",
    "fs_X_train_path = (data_splits_dir / \"fs_X_train.csv.gz\").resolve(strict=True)\n",
    "fs_X_test_path = (data_splits_dir / \"fs_X_test.csv.gz\").resolve(strict=True)\n",
    "fs_y_train_path = (data_splits_dir / \"fs_y_train.csv.gz\").resolve(strict=True)\n",
    "fs_y_test_path = (data_splits_dir / \"fs_y_test.csv.gz\").resolve(strict=True)\n",
    "\n",
    "# setting feature selected holdouts data paths\n",
    "fs_plate_holdout_path = (data_splits_dir / \"fs_plate_holdout.csv.gz\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "fs_treatment_holdout_path = (data_splits_dir / \"fs_treatment_holdout.csv.gz\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "fs_well_holdout_path = (data_splits_dir / \"fs_well_holdout.csv.gz\").resolve(strict=True)\n",
    "\n",
    "# set injury codes path\n",
    "injury_codes_path = (feature_dir / \"injury_codes.json\").resolve(strict=True)\n",
    "\n",
    "# setting feature spaces paths\n",
    "fs_feature_space_path = (\n",
    "    feature_dir / \"fs_cell_injury_only_feature_space.json\"\n",
    ").resolve(strict=True)\n",
    "aligned_feature_space_path = (\n",
    "    feature_dir / \"aligned_cell_injury_shared_feature_space.json\"\n",
    ").resolve(strict=True)\n",
    "\n",
    "# setting output paths\n",
    "modeling_dir = (results_dir / \"2.modeling\").resolve()\n",
    "modeling_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# setting model paths\n",
    "fs_model_path = modeling_dir / \"fs_multi_class_model.joblib\"\n",
    "fs_shuffled_model_path = modeling_dir / \"fs_shuffled_multi_class_model.joblib\"\n",
    "\n",
    "aligned_model_path = modeling_dir / \"aligned_multi_class_model.joblib\"\n",
    "aligned_shuffled_model_path = modeling_dir / \"aligned_shuffled_multi_class_model.joblib\"\n",
    "\n",
    "# setting cross-validations scores paths\n",
    "fs_model_cv_results_path = modeling_dir / \"fs_multi_class_cv_results.csv\"\n",
    "fs_shuffled_model_cv_results_path = (\n",
    "    modeling_dir / \"fs_shuffled_multi_class_cv_results.csv\"\n",
    ")\n",
    "\n",
    "aligned_model_cv_results_path = modeling_dir / \"aligned_multi_class_cv_results.csv\"\n",
    "aligned_shuffled_model_cv_results_path = (\n",
    "    modeling_dir / \"aligned_shuffled_multi_class_cv_results.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data splits\n",
    "aligned_X_train_df = pd.read_csv(aligned_X_train_path)\n",
    "aligned_X_test_df = pd.read_csv(aligned_X_test_path)\n",
    "aligned_y_train_df = pd.read_csv(aligned_y_train_path)\n",
    "aligned_y_test_df = pd.read_csv(aligned_y_test_path)\n",
    "\n",
    "fs_X_train_df = pd.read_csv(fs_X_train_path)\n",
    "fs_X_test_df = pd.read_csv(fs_X_test_path)\n",
    "fs_y_train_df = pd.read_csv(fs_y_train_path)\n",
    "fs_y_test_df = pd.read_csv(fs_y_test_path)\n",
    "\n",
    "# loading fs_holdouts\n",
    "fs_plate_holdout_df = pd.read_csv(fs_plate_holdout_path)\n",
    "fs_treatment_holdout_df = pd.read_csv(fs_treatment_holdout_path)\n",
    "fs_well_holdout_df = pd.read_csv(fs_well_holdout_path)\n",
    "\n",
    "# load injury codes\n",
    "injury_codes = load_json_file(injury_codes_path)\n",
    "\n",
    "# loading feature spaces\n",
    "fs_feature_space = load_json_file(fs_feature_space_path)\n",
    "aligned_feature_space = load_json_file(aligned_feature_space_path)\n",
    "\n",
    "fs_meta = fs_feature_space[\"meta_features\"]\n",
    "fs_feats = fs_feature_space[\"features\"]\n",
    "\n",
    "aligned_aligned = aligned_feature_space[\"meta_features\"]\n",
    "aligned_feats = aligned_feature_space[\"features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating Multi-class Logistic model with feature selected cell injury profiles (not jump aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the parameters used:\n",
    "\n",
    "- **penalty**: Specifies the type of penalty (regularization) applied during logistic regression. It can be 'l1' for L1 regularization, 'l2' for L2 regularization, or 'elasticnet' for a combination of both.\n",
    "- **C**: Inverse of regularization strength; smaller values specify stronger regularization. Controls the trade-off between fitting the training data and preventing overfitting.\n",
    "- **max_iter**: Maximum number of iterations for the optimization algorithm to converge.\n",
    "- **tol**: Tolerance for the stopping criterion during optimization. It represents the minimum change in coefficients between iterations that indicates convergence.\n",
    "- **l1_ratio**: The mixing parameter for elastic net regularization. It determines the balance between L1 and L2 penalties in the regularization term. A value of 1 corresponds to pure L1 (Lasso) penalty, while a value of 0 corresponds to pure L2 (Ridge) penalty\n",
    "- **solver**: Optimization algorithms to be explored during hyperparameter tuning for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"max_iter\": np.arange(100, 1100, 100),\n",
    "    \"tol\": np.arange(1e-6, 1e-3, 1e-6),\n",
    "    \"l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training both non shuffled and shuffled models with feature selected cell injury profiles (not aligned with JUMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if trained model exists, skip training\n",
    "if fs_model_path.exists():\n",
    "    fs_best_model = joblib.load(fs_model_path)\n",
    "\n",
    "# train model and save\n",
    "else:\n",
    "    fs_best_model = train_multiclass(\n",
    "        fs_X_train_df,\n",
    "        fs_y_train_df,\n",
    "        param_grid=param_grid,\n",
    "        seed=seed,\n",
    "        cv_results_outpath=fs_model_cv_results_path,\n",
    "    )\n",
    "    joblib.dump(fs_best_model, fs_model_path)\n",
    "\n",
    "\n",
    "# Training shuffled model\n",
    "# shuffle feature space\n",
    "fs_shuffled_X_train = shuffle_features(fs_X_train_df, features=fs_feats, seed=seed)\n",
    "\n",
    "# checking if the shuffled and original feature space are the same\n",
    "assert not fs_X_train_df.equals(fs_shuffled_X_train), \"DataFrames are the same!\"\n",
    "\n",
    "# if trained model exists, skip training\n",
    "if fs_shuffled_model_path.exists():\n",
    "    fs_shuffled_best_model = joblib.load(fs_shuffled_model_path)\n",
    "\n",
    "\n",
    "# train model and save\n",
    "else:\n",
    "    fs_shuffled_best_model = train_multiclass(\n",
    "        fs_shuffled_X_train,\n",
    "        fs_y_train_df,\n",
    "        param_grid=param_grid,\n",
    "        seed=seed,\n",
    "        cv_results_outpath=fs_shuffled_model_cv_results_path,\n",
    "    )\n",
    "    joblib.dump(fs_shuffled_best_model, fs_shuffled_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating both shuffled and non shuffled models with original data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model on train dataset\n",
    "train_precision_recall_df, train_f1_score_df = evaluate_model_performance(\n",
    "    model=fs_best_model,\n",
    "    X=fs_X_train_df,\n",
    "    y=fs_y_train_df,\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Train\",\n",
    ")\n",
    "\n",
    "# evaluating model on test dataset\n",
    "test_precision_recall_df, test_f1_score_df = evaluate_model_performance(\n",
    "    model=fs_best_model,\n",
    "    X=fs_X_test_df,\n",
    "    y=fs_y_test_df,\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating shuffled model on train dataset\n",
    "shuffle_train_precision_recall_df, shuffle_train_f1_score_df = (\n",
    "    evaluate_model_performance(\n",
    "        model=fs_shuffled_best_model,\n",
    "        X=fs_shuffled_X_train,\n",
    "        y=fs_y_train_df,\n",
    "        shuffled=True,\n",
    "        dataset_type=\"Train\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# evaluating shuffled model on test dataset\n",
    "shuffle_test_precision_recall_df, shuffle_test_f1_score_df = evaluate_model_performance(\n",
    "    model=fs_shuffled_best_model,\n",
    "    X=fs_X_test_df,\n",
    "    y=fs_y_test_df,\n",
    "    shuffled=True,\n",
    "    dataset_type=\"Test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating confusion matrix with both shuffle and non shuffled models with original data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating confusion matrix for both train and test set on non-shuffled model\n",
    "cm_train_df = generate_confusion_matrix_tl(\n",
    "    model=fs_best_model,\n",
    "    X=fs_X_train_df,\n",
    "    y=fs_y_train_df,\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Train\",\n",
    ")\n",
    "cm_test_df = generate_confusion_matrix_tl(\n",
    "    model=fs_best_model,\n",
    "    X=fs_X_test_df,\n",
    "    y=fs_y_test_df,\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating confusion matrix for shuffled model\n",
    "shuffled_cm_train_df = generate_confusion_matrix_tl(\n",
    "    model=fs_shuffled_best_model,\n",
    "    X=fs_shuffled_X_train,\n",
    "    y=fs_y_train_df,\n",
    "    shuffled=True,\n",
    "    dataset_type=\"Train\",\n",
    ")\n",
    "shuffled_cm_test_df = generate_confusion_matrix_tl(\n",
    "    model=fs_shuffled_best_model,\n",
    "    X=fs_X_test_df,\n",
    "    y=fs_y_test_df,\n",
    "    shuffled=True,\n",
    "    dataset_type=\"Test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating both shuffled and non Multi-class model with holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating plate holdout data with both trained original and shuffled model\n",
    "plate_ho_precision_recall_df, plate_ho_f1_score_df = evaluate_model_performance(\n",
    "    model=fs_best_model,\n",
    "    X=fs_plate_holdout_df[fs_feats],\n",
    "    y=fs_plate_holdout_df[\"injury_code\"],\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Plate Holdout\",\n",
    ")\n",
    "\n",
    "plate_ho_shuffle_precision_recall_df, plate_ho_shuffle_f1_score_df = (\n",
    "    evaluate_model_performance(\n",
    "        model=fs_shuffled_best_model,\n",
    "        X=fs_plate_holdout_df[fs_feats],\n",
    "        y=fs_plate_holdout_df[\"injury_code\"],\n",
    "        shuffled=True,\n",
    "        dataset_type=\"Plate Holdout\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# evaluating treatment holdout data with both trained original and shuffled model\n",
    "treatment_ho_precision_recall_df, treatment_ho_f1_score_df = evaluate_model_performance(\n",
    "    model=fs_best_model,\n",
    "    X=fs_treatment_holdout_df[fs_feats],\n",
    "    y=fs_treatment_holdout_df[\"injury_code\"],\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Treatment Holdout\",\n",
    ")\n",
    "\n",
    "treatment_ho_shuffle_precision_recall_df, treatment_ho_shuffle_f1_score_df = (\n",
    "    evaluate_model_performance(\n",
    "        model=fs_shuffled_best_model,\n",
    "        X=fs_treatment_holdout_df[fs_feats],\n",
    "        y=fs_treatment_holdout_df[\"injury_code\"],\n",
    "        shuffled=True,\n",
    "        dataset_type=\"Treatment Holdout\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# evaluating well holdout data with both trained original and shuffled model\n",
    "well_ho_precision_recall_df, well_ho_f1_score_df = evaluate_model_performance(\n",
    "    model=fs_best_model,\n",
    "    X=fs_well_holdout_df[fs_feats],\n",
    "    y=fs_well_holdout_df[\"injury_code\"],\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Well Holdout\",\n",
    ")\n",
    "\n",
    "well_ho_shuffle_precision_recall_df, well_ho_shuffle_f1_score_df = (\n",
    "    evaluate_model_performance(\n",
    "        model=fs_shuffled_best_model,\n",
    "        X=fs_well_holdout_df[fs_feats],\n",
    "        y=fs_well_holdout_df[\"injury_code\"],\n",
    "        shuffled=True,\n",
    "        dataset_type=\"Well Holdout\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating confusion matrix with both shuffle and non shuffled models with holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating confusion matrix with plate holdout (shuffled and not shuffled)\n",
    "plate_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=fs_best_model,\n",
    "    X=fs_plate_holdout_df[fs_feats],\n",
    "    y=fs_plate_holdout_df[\"injury_code\"],\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Plate Holdout\",\n",
    ")\n",
    "shuffled_plate_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=fs_shuffled_best_model,\n",
    "    X=fs_plate_holdout_df[fs_feats],\n",
    "    y=fs_plate_holdout_df[\"injury_code\"],\n",
    "    shuffled=True,\n",
    "    dataset_type=\"Plate Holdout\",\n",
    ")\n",
    "\n",
    "# creating confusion matrix with treatment holdout (shuffled and not shuffled)\n",
    "treatment_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=fs_best_model,\n",
    "    X=fs_treatment_holdout_df[fs_feats],\n",
    "    y=fs_treatment_holdout_df[\"injury_code\"],\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Treatment Holdout\",\n",
    ")\n",
    "shuffled_treatment_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=fs_shuffled_best_model,\n",
    "    X=fs_treatment_holdout_df[fs_feats],\n",
    "    y=fs_treatment_holdout_df[\"injury_code\"],\n",
    "    shuffled=True,\n",
    "    dataset_type=\"Treatment Holdout\",\n",
    ")\n",
    "\n",
    "# creating confusion matrix with plate_hold (shuffled and not shuffled)\n",
    "well_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=fs_best_model,\n",
    "    X=fs_well_holdout_df[fs_feats],\n",
    "    y=fs_well_holdout_df[\"injury_code\"],\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Well Holdout\",\n",
    ")\n",
    "shuffled_well_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=fs_shuffled_best_model,\n",
    "    X=fs_well_holdout_df[fs_feats],\n",
    "    y=fs_well_holdout_df[\"injury_code\"],\n",
    "    shuffled=True,\n",
    "    dataset_type=\"Well Holdout\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving all model evaluations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing all f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing all f1 scores\n",
    "all_f1_scores = pd.concat(\n",
    "    [\n",
    "        # original split\n",
    "        test_f1_score_df,\n",
    "        train_f1_score_df,\n",
    "        # shuffle split\n",
    "        shuffle_test_f1_score_df,\n",
    "        shuffle_train_f1_score_df,\n",
    "        # plate holdout\n",
    "        plate_ho_f1_score_df,\n",
    "        plate_ho_shuffle_f1_score_df,\n",
    "        # treatment holdout\n",
    "        treatment_ho_f1_score_df,\n",
    "        treatment_ho_shuffle_f1_score_df,\n",
    "        # well holdout\n",
    "        well_ho_f1_score_df,\n",
    "        well_ho_shuffle_f1_score_df,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# saving all f1 scores\n",
    "all_f1_scores.to_csv(\n",
    "    modeling_dir / \"fs_all_f1_scores.csv.gz\", index=False, compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving all precision and recall scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing pr scores\n",
    "all_pr_scores = pd.concat(\n",
    "    [\n",
    "        # original split\n",
    "        test_precision_recall_df,\n",
    "        train_precision_recall_df,\n",
    "        # shuffled split\n",
    "        shuffle_test_precision_recall_df,\n",
    "        shuffle_train_precision_recall_df,\n",
    "        # plate holdout\n",
    "        plate_ho_precision_recall_df,\n",
    "        plate_ho_shuffle_precision_recall_df,\n",
    "        # treatment holdout\n",
    "        treatment_ho_precision_recall_df,\n",
    "        treatment_ho_shuffle_precision_recall_df,\n",
    "        # well holdout\n",
    "        well_ho_precision_recall_df,\n",
    "        well_ho_shuffle_precision_recall_df,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# saving pr scores\n",
    "all_pr_scores.to_csv(\n",
    "    modeling_dir / \"fs_precision_recall_scores.csv.gz\", index=False, compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving all confusion matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cm_dfs = pd.concat(\n",
    "    [\n",
    "        # original split\n",
    "        cm_train_df,\n",
    "        cm_test_df,\n",
    "        # shuffled split\n",
    "        shuffled_cm_train_df,\n",
    "        shuffled_cm_test_df,\n",
    "        # plate holdout\n",
    "        plate_ho_cm_df,\n",
    "        shuffled_plate_ho_cm_df,\n",
    "        # treatment holdout\n",
    "        treatment_ho_cm_df,\n",
    "        shuffled_treatment_ho_cm_df,\n",
    "        # well holdout\n",
    "        well_ho_cm_df,\n",
    "        shuffled_well_ho_cm_df,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# saving pr scores\n",
    "all_cm_dfs.to_csv(\n",
    "    modeling_dir / \"fs_confusion_matrix.csv.gz\", index=False, compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with JUMP aligned feature selected cell injury profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if trained aligned model exists, skip training\n",
    "if aligned_model_path.exists():\n",
    "    aligned_best_model = joblib.load(aligned_model_path)\n",
    "\n",
    "# train model with aligned cell injury profiles and save\n",
    "else:\n",
    "    aligned_best_model = train_multiclass(\n",
    "        aligned_X_train_df[aligned_feats],\n",
    "        aligned_y_train_df[\"injury_code\"],\n",
    "        param_grid=param_grid,\n",
    "        seed=seed,\n",
    "        cv_results_outpath=aligned_model_cv_results_path,\n",
    "    )\n",
    "    joblib.dump(aligned_best_model, aligned_model_path)\n",
    "\n",
    "\n",
    "# Training shuffled model\n",
    "# shuffle feature space\n",
    "aligned_shuffled_X_train = shuffle_features(\n",
    "    aligned_X_train_df, features=aligned_feats, seed=seed\n",
    ")\n",
    "\n",
    "# checking if the shuffled and original feature space are the same\n",
    "assert not aligned_X_train_df.equals(\n",
    "    aligned_shuffled_X_train\n",
    "), \"DataFrames are the same!\"\n",
    "\n",
    "# if trained shuffled aligned model exists, skip training\n",
    "if aligned_shuffled_model_path.exists():\n",
    "    aligned_shuffled_best_model = joblib.load(aligned_shuffled_model_path)\n",
    "\n",
    "# train model with shuffled aligned cell injury data and save\n",
    "else:\n",
    "    aligned_shuffled_best_model = train_multiclass(\n",
    "        aligned_shuffled_X_train[aligned_feats],\n",
    "        aligned_y_train_df[\"injury_code\"],\n",
    "        param_grid=param_grid,\n",
    "        seed=seed,\n",
    "        cv_results_outpath=aligned_shuffled_model_cv_results_path,\n",
    "    )\n",
    "    joblib.dump(aligned_shuffled_best_model, aligned_shuffled_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting coefficient scores\n",
    "\n",
    "Next, we will extract the coefficient scores for all morphological features for each class and save the results into a single CSV file.\n",
    "\n",
    "The generated CSV file will include the following columns:\n",
    "- **injury_id**: A numeric identifier assigned to each injury type.\n",
    "- **injury_name**: The name of the injury type.\n",
    "- **feature**: The name of the morphological feature.\n",
    "- **coefficient**: The coefficient score associated with the morphological feature for the specific injury class.\n",
    "- **model_name**: The name of the model that generated the scores, good for tracking.\n",
    "\n",
    "This file will allow for easy examination of the importance of each feature in predicting different injury types, facilitating a deeper understanding of the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>injury_code</th>\n",
       "      <th>injury_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>abs_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Control</td>\n",
       "      <td>fs_model</td>\n",
       "      <td>Cytoplasm_Intensity_MADIntensity_ER</td>\n",
       "      <td>-1.152483</td>\n",
       "      <td>1.152483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Control</td>\n",
       "      <td>fs_model</td>\n",
       "      <td>Cytoplasm_Texture_SumAverage_ER_5_0</td>\n",
       "      <td>-1.061044</td>\n",
       "      <td>1.061044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Control</td>\n",
       "      <td>fs_model</td>\n",
       "      <td>Nuclei_Intensity_MinIntensity_AGP</td>\n",
       "      <td>-0.993742</td>\n",
       "      <td>0.993742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Control</td>\n",
       "      <td>fs_model</td>\n",
       "      <td>Cells_Intensity_IntegratedIntensity_AGP</td>\n",
       "      <td>-0.980258</td>\n",
       "      <td>0.980258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Control</td>\n",
       "      <td>fs_model</td>\n",
       "      <td>Nuclei_Intensity_IntegratedIntensityEdge_AGP</td>\n",
       "      <td>-0.960757</td>\n",
       "      <td>0.960757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   injury_code injury_name model_type  \\\n",
       "0            0     Control   fs_model   \n",
       "1            0     Control   fs_model   \n",
       "2            0     Control   fs_model   \n",
       "3            0     Control   fs_model   \n",
       "4            0     Control   fs_model   \n",
       "\n",
       "                                        feature  coefficient  abs_coefficient  \n",
       "0           Cytoplasm_Intensity_MADIntensity_ER    -1.152483         1.152483  \n",
       "1           Cytoplasm_Texture_SumAverage_ER_5_0    -1.061044         1.061044  \n",
       "2             Nuclei_Intensity_MinIntensity_AGP    -0.993742         0.993742  \n",
       "3       Cells_Intensity_IntegratedIntensity_AGP    -0.980258         0.980258  \n",
       "4  Nuclei_Intensity_IntegratedIntensityEdge_AGP    -0.960757         0.960757  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting coefficient scores from both models\n",
    "fs_coeff_df = get_coeff_scores(\n",
    "    best_model=fs_best_model,\n",
    "    features=fs_feats,\n",
    "    injury_codes=injury_codes,\n",
    "    model_name=\"fs_model\",\n",
    ")\n",
    "aligned_coeff_df = get_coeff_scores(\n",
    "    best_model=aligned_best_model,\n",
    "    features=aligned_feats,\n",
    "    injury_codes=injury_codes,\n",
    "    model_name=\"JUMP_aligned_model\",\n",
    ")\n",
    "\n",
    "# concatenating the coefficient scores\n",
    "all_coeff_scores = pd.concat(\n",
    "    [\n",
    "        fs_coeff_df,\n",
    "        aligned_coeff_df,\n",
    "    ]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# save\n",
    "all_coeff_scores.to_csv(modeling_dir / \"all_model_coeff_scores.csv\", index=False)\n",
    "\n",
    "# display\n",
    "all_coeff_scores.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell-injury",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
