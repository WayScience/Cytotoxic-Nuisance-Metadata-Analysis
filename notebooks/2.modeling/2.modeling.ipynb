{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Modeling \n",
    "\n",
    "In this notebook, we focus on developing and training a Multi-class logistic regression model, employing Randomized Cross-Validation (CV) for hyperparameter tuning to address our classification task. The dataset is split into an 80% training set and a 20% testing set. To evaluate the performance of our model during training, we used performance evaluation metrics such as precision, recall, and F1 scores. Additionally, we extend our evaluation by testing our model on a holdout dataset, which includes plate, treatment, and well information, providing a comprehensive assessment of its real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import local modules\n",
    "sys.path.append(\"../../\")\n",
    "from src.utils import (\n",
    "    train_multiclass,\n",
    "    shuffle_features,\n",
    "    load_json_file,\n",
    "    check_feature_order,\n",
    "    generate_confusion_matrix_tl,\n",
    "    evaluate_model_performance,\n",
    "    split_meta_and_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting random seeds variables\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "# setting paths and parameters\n",
    "results_dir = pathlib.Path(\"../../results\").resolve(strict=True)\n",
    "feature_dir = (results_dir / \"0.feature_selection/\").resolve(strict=True)\n",
    "data_splits_dir = (results_dir / \"1.data_splits\").resolve(strict=True)\n",
    "\n",
    "# test and train data paths\n",
    "X_train_path = (data_splits_dir / \"X_train.csv.gz\").resolve(strict=True)\n",
    "X_test_path = (data_splits_dir / \"X_test.csv.gz\").resolve(strict=True)\n",
    "y_train_path = (data_splits_dir / \"y_train.csv.gz\").resolve(strict=True)\n",
    "y_test_path = (data_splits_dir / \"y_test.csv.gz\").resolve(strict=True)\n",
    "\n",
    "# shared feature space path\n",
    "feature_space_path = (feature_dir / \"cell_injury_shared_feature_space.json\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "\n",
    "# holdout paths\n",
    "plate_holdout_path = (data_splits_dir / \"plate_holdout.csv.gz\").resolve(strict=True)\n",
    "treatment_holdout_path = (data_splits_dir / \"treatment_holdout.csv.gz\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "wells_holdout_path = (data_splits_dir / \"wells_holdout.csv.gz\").resolve(strict=True)\n",
    "\n",
    "# setting output paths\n",
    "modeling_dir = (results_dir / \"2.modeling\").resolve()\n",
    "modeling_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the parameters used:\n",
    "\n",
    "- **penalty**: Specifies the type of penalty (regularization) applied during logistic regression. It can be 'l1' for L1 regularization, 'l2' for L2 regularization, or 'elasticnet' for a combination of both.\n",
    "- **C**: Inverse of regularization strength; smaller values specify stronger regularization. Controls the trade-off between fitting the training data and preventing overfitting.\n",
    "- **max_iter**: Maximum number of iterations for the optimization algorithm to converge.\n",
    "- **tol**: Tolerance for the stopping criterion during optimization. It represents the minimum change in coefficients between iterations that indicates convergence.\n",
    "- **l1_ratio**: The mixing parameter for elastic net regularization. It determines the balance between L1 and L2 penalties in the regularization term. A value of 1 corresponds to pure L1 (Lasso) penalty, while a value of 0 corresponds to pure L2 (Ridge) penalty\n",
    "- **solver**: Optimization algorithms to be explored during hyperparameter tuning for logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "param_grid = {\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"max_iter\": np.arange(100, 1100, 100),\n",
    "    \"tol\": np.arange(1e-6, 1e-3, 1e-6),\n",
    "    \"l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading training data splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training size (10802, 221)\n",
      "X testing size (2701, 221)\n",
      "y training size (10802, 1)\n",
      "y testing size (2701, 1)\n"
     ]
    }
   ],
   "source": [
    "# loading injury codes\n",
    "injury_codes = load_json_file(feature_dir / \"injury_codes.json\")\n",
    "\n",
    "# load share feature space data\n",
    "feature_space = load_json_file(feature_space_path)\n",
    "shared_features = feature_space[\"features\"]\n",
    "\n",
    "# loading training data splits\n",
    "X_train = pd.read_csv(X_train_path)\n",
    "X_test = pd.read_csv(X_test_path)\n",
    "y_train = pd.read_csv(y_train_path)\n",
    "y_test = pd.read_csv(y_test_path)\n",
    "\n",
    "\n",
    "# splitting meta and feature column names\n",
    "_, feat_cols = split_meta_and_features(X_train)\n",
    "\n",
    "# checking if the feature space are identical (also looks for feature space order)\n",
    "assert check_feature_order(\n",
    "    ref_feat_order=shared_features, input_feat_order=X_test.columns.tolist()\n",
    "), \"Feature space are not identical\"\n",
    "\n",
    "# display data split sizes\n",
    "print(\"X training size\", X_train.shape)\n",
    "print(\"X testing size\", X_test.shape)\n",
    "print(\"y training size\", y_train.shape)\n",
    "print(\"y testing size\", y_test.shape)  #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating Multi-class Logistic Model with original dataset split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model path\n",
    "model_path = modeling_dir / \"multi_class_model.joblib\"\n",
    "\n",
    "# if trained model exists, skip training\n",
    "if model_path.exists():\n",
    "    best_model = joblib.load(model_path)\n",
    "\n",
    "# train model and save\n",
    "else:\n",
    "    best_model = train_multiclass(X_train, y_train, param_grid=param_grid, seed=seed)\n",
    "    joblib.dump(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model on train dataset\n",
    "train_precision_recall_df, train_f1_score_df = evaluate_model_performance(\n",
    "    model=best_model, X=X_train, y=y_train, shuffled=False, dataset_type=\"Train\"\n",
    ")\n",
    "\n",
    "# evaluating model on test dataset\n",
    "test_precision_recall_df, test_f1_score_df = evaluate_model_performance(\n",
    "    model=best_model, X=X_test, y=y_test, shuffled=False, dataset_type=\"Test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating confusion matrix for both train and test set on non-shuffled model\n",
    "cm_train_df = generate_confusion_matrix_tl(\n",
    "    model=best_model, X=X_train, y=y_train, shuffled=False, dataset_type=\"Train\"\n",
    ")\n",
    "cm_test_df = generate_confusion_matrix_tl(\n",
    "    model=best_model, X=X_test, y=y_test, shuffled=False, dataset_type=\"Test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating Multi-class Logistic Model with shuffled dataset split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle feature space\n",
    "shuffled_X_train = shuffle_features(X_train, features=shared_features, seed=seed)\n",
    "\n",
    "# checking if the shuffled and original feature space are the same\n",
    "assert not X_train.equals(shuffled_X_train), \"DataFrames are the same!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model path\n",
    "shuffled_model_path = modeling_dir / \"shuffled_multi_class_model.joblib\"\n",
    "\n",
    "# if trained model exists, skip training\n",
    "if shuffled_model_path.exists():\n",
    "    shuffled_best_model = joblib.load(shuffled_model_path)\n",
    "\n",
    "# train model and save\n",
    "else:\n",
    "    shuffled_best_model = train_multiclass(\n",
    "        shuffled_X_train, y_train, param_grid=param_grid, seed=seed\n",
    "    )\n",
    "    joblib.dump(shuffled_best_model, shuffled_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating shuffled model on train dataset\n",
    "shuffle_train_precision_recall_df, shuffle_train_f1_score_df = (\n",
    "    evaluate_model_performance(\n",
    "        model=shuffled_best_model,\n",
    "        X=shuffled_X_train,\n",
    "        y=y_train,\n",
    "        shuffled=True,\n",
    "        dataset_type=\"Train\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# valuating shuffled model on test dataset\n",
    "shuffle_test_precision_recall_df, shuffle_test_f1_score_df = evaluate_model_performance(\n",
    "    model=shuffled_best_model, X=X_test, y=y_test, shuffled=True, dataset_type=\"Test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating confusion matrix for shuffled model\n",
    "shuffled_cm_train_df = generate_confusion_matrix_tl(\n",
    "    model=shuffled_best_model,\n",
    "    X=shuffled_X_train,\n",
    "    y=y_train,\n",
    "    shuffled=True,\n",
    "    dataset_type=\"Train\",\n",
    ")\n",
    "shuffled_cm_test_df = generate_confusion_matrix_tl(\n",
    "    model=shuffled_best_model, X=X_test, y=y_test, shuffled=True, dataset_type=\"Test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Multi-class model with holdout data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in all the hold out data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all holdouts\n",
    "plate_holdout_df = pd.read_csv(plate_holdout_path)\n",
    "treatment_holdout_df = pd.read_csv(treatment_holdout_path)\n",
    "well_holdout_df = pd.read_csv(wells_holdout_path)\n",
    "\n",
    "# splitting the dataset into X = features , y = injury_types\n",
    "X_plate_holdout = plate_holdout_df[feat_cols]\n",
    "y_plate_holdout = plate_holdout_df[\"injury_code\"]\n",
    "\n",
    "X_treatment_holdout = treatment_holdout_df[feat_cols]\n",
    "y_treatment_holdout = treatment_holdout_df[\"injury_code\"]\n",
    "\n",
    "X_well_holdout = well_holdout_df[feat_cols]\n",
    "y_well_holdout = well_holdout_df[\"injury_code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Multi-class model trained with original split with holdout data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating plate holdout data with both trained original and shuffled model\n",
    "plate_ho_precision_recall_df, plate_ho_f1_score_df = evaluate_model_performance(\n",
    "    model=best_model,\n",
    "    X=X_plate_holdout,\n",
    "    y=y_plate_holdout,\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Plate Holdout\",\n",
    ")\n",
    "\n",
    "plate_ho_shuffle_precision_recall_df, plate_ho_shuffle_f1_score_df = (\n",
    "    evaluate_model_performance(\n",
    "        model=shuffled_best_model,\n",
    "        X=X_plate_holdout,\n",
    "        y=y_plate_holdout,\n",
    "        shuffled=True,\n",
    "        dataset_type=\"Plate Holdout\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# evaluating treatment holdout data with both trained original and shuffled model\n",
    "treatment_ho_precision_recall_df, treatment_ho_f1_score_df = evaluate_model_performance(\n",
    "    model=best_model,\n",
    "    X=X_treatment_holdout,\n",
    "    y=y_treatment_holdout,\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Treatment Holdout\",\n",
    ")\n",
    "\n",
    "treatment_ho_shuffle_precision_recall_df, treatment_ho_shuffle_f1_score_df = (\n",
    "    evaluate_model_performance(\n",
    "        model=shuffled_best_model,\n",
    "        X=X_treatment_holdout,\n",
    "        y=y_treatment_holdout,\n",
    "        shuffled=True,\n",
    "        dataset_type=\"Treatment Holdout\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# evaluating well holdout data with both trained original and shuffled model\n",
    "well_ho_precision_recall_df, well_ho_f1_score_df = evaluate_model_performance(\n",
    "    model=best_model,\n",
    "    X=X_well_holdout,\n",
    "    y=y_well_holdout,\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Well Holdout\",\n",
    ")\n",
    "\n",
    "well_ho_shuffle_precision_recall_df, well_ho_shuffle_f1_score_df = (\n",
    "    evaluate_model_performance(\n",
    "        model=shuffled_best_model,\n",
    "        X=X_well_holdout,\n",
    "        y=y_well_holdout,\n",
    "        shuffled=True,\n",
    "        dataset_type=\"Well Holdout\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating confusion matrix with plate holdout (shuffled and not shuffled)\n",
    "plate_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=best_model,\n",
    "    X=X_plate_holdout,\n",
    "    y=y_plate_holdout,\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Plate Holdout\",\n",
    ")\n",
    "shuffled_plate_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=shuffled_best_model,\n",
    "    X=X_plate_holdout,\n",
    "    y=y_plate_holdout,\n",
    "    shuffled=True,\n",
    "    dataset_type=\"Plate Holdout\",\n",
    ")\n",
    "\n",
    "# creating confusion matrix with treatment holdout (shuffled and not shuffled)\n",
    "treatment_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=best_model,\n",
    "    X=X_treatment_holdout,\n",
    "    y=y_treatment_holdout,\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Treatment Holdout\",\n",
    ")\n",
    "shuffled_treatment_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=shuffled_best_model,\n",
    "    X=X_treatment_holdout,\n",
    "    y=y_treatment_holdout,\n",
    "    shuffled=True,\n",
    "    dataset_type=\"Treatment Holdout\",\n",
    ")\n",
    "\n",
    "# creating confusion matrix with plate_hold (shuffled and not shuffled)\n",
    "well_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=best_model,\n",
    "    X=X_well_holdout,\n",
    "    y=y_well_holdout,\n",
    "    shuffled=False,\n",
    "    dataset_type=\"Well Holdout\",\n",
    ")\n",
    "shuffled_well_ho_cm_df = generate_confusion_matrix_tl(\n",
    "    model=shuffled_best_model,\n",
    "    X=X_well_holdout,\n",
    "    y=y_well_holdout,\n",
    "    shuffled=True,\n",
    "    dataset_type=\"Well Holdout\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing all f1 and pr scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing all f1 scores\n",
    "all_f1_scores = pd.concat(\n",
    "    [\n",
    "        # original split\n",
    "        test_f1_score_df,\n",
    "        train_f1_score_df,\n",
    "        # shuffle split\n",
    "        shuffle_test_f1_score_df,\n",
    "        shuffle_train_f1_score_df,\n",
    "        # plate holdout\n",
    "        plate_ho_f1_score_df,\n",
    "        plate_ho_shuffle_f1_score_df,\n",
    "        # treatment holdout\n",
    "        treatment_ho_f1_score_df,\n",
    "        treatment_ho_shuffle_f1_score_df,\n",
    "        # well holdout\n",
    "        well_ho_f1_score_df,\n",
    "        well_ho_shuffle_f1_score_df,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# saving all f1 scores\n",
    "all_f1_scores.to_csv(\n",
    "    modeling_dir / \"all_f1_scores.csv.gz\", index=False, compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing pr scores\n",
    "all_pr_scores = pd.concat(\n",
    "    [\n",
    "        # original split\n",
    "        test_precision_recall_df,\n",
    "        train_precision_recall_df,\n",
    "        # shuffled split\n",
    "        shuffle_test_precision_recall_df,\n",
    "        shuffle_train_precision_recall_df,\n",
    "        # plate holdout\n",
    "        plate_ho_precision_recall_df,\n",
    "        plate_ho_shuffle_precision_recall_df,\n",
    "        # treatment holdout\n",
    "        treatment_ho_precision_recall_df,\n",
    "        treatment_ho_shuffle_precision_recall_df,\n",
    "        # well holdout\n",
    "        well_ho_precision_recall_df,\n",
    "        well_ho_shuffle_precision_recall_df,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# saving pr scores\n",
    "all_pr_scores.to_csv(\n",
    "    modeling_dir / \"precision_recall_scores.csv.gz\", index=False, compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cm_dfs = pd.concat(\n",
    "    [\n",
    "        # original split\n",
    "        cm_train_df,\n",
    "        cm_test_df,\n",
    "        # shuffled split\n",
    "        shuffled_cm_train_df,\n",
    "        shuffled_cm_test_df,\n",
    "        # plate holdout\n",
    "        plate_ho_cm_df,\n",
    "        shuffled_plate_ho_cm_df,\n",
    "        # treatment holdout\n",
    "        treatment_ho_cm_df,\n",
    "        shuffled_treatment_ho_cm_df,\n",
    "        # well holdout\n",
    "        well_ho_cm_df,\n",
    "        shuffled_well_ho_cm_df,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# saving pr scores\n",
    "all_cm_dfs.to_csv(\n",
    "    modeling_dir / \"confusion_matrix.csv.gz\", index=False, compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will extract the coefficient scores for all morphological features for each class and save the results into a single CSV file.\n",
    "\n",
    "The generated CSV file will include the following columns:\n",
    "- **injury_id**: A numeric identifier assigned to each injury type.\n",
    "- **injury_name**: The name of the injury type.\n",
    "- **feature**: The name of the morphological feature.\n",
    "- **coefficient**: The coefficient score associated with the morphological feature for the specific injury class.\n",
    "\n",
    "This file will allow for easy examination of the importance of each feature in predicting different injury types, facilitating a deeper understanding of the model's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "# get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# get coeff scores\n",
    "scores = best_model.coef_\n",
    "\n",
    "# creating a data frame that contains the injury code, injury name and coef scores\n",
    "coef_score_df = (\n",
    "    pd.DataFrame(data=scores, columns=feature_names)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"injury_name\"})\n",
    ")\n",
    "coef_score_df[\"injury_name\"] = coef_score_df[\"injury_name\"].apply(\n",
    "    lambda code: injury_codes[\"decoder\"][str(code)]\n",
    ")\n",
    "coef_score_df = coef_score_df.reset_index().rename(columns={\"index\": \"injury_code\"})\n",
    "\n",
    "# Melt the DataFrame from wide to long format\n",
    "# Converts the DataFrame to have 'injury_code', 'injury_name', 'feature', and 'coefficient' columns\n",
    "score_group = pd.melt(\n",
    "    coef_score_df,\n",
    "    id_vars=[\"injury_code\", \"injury_name\"],\n",
    "    var_name=\"feature\",\n",
    "    value_name=\"coefficient\",\n",
    ").groupby(by=\"injury_code\")\n",
    "\n",
    "# Initialize a list to hold sorted DataFrames\n",
    "sorted_scores = []\n",
    "\n",
    "# Iterate over each group\n",
    "for score, df in score_group:\n",
    "    # Sort the DataFrame by 'coefficient' in descending order\n",
    "    df = df.sort_values(by=\"coefficient\", ascending=False)\n",
    "\n",
    "    # Append the sorted DataFrame to the list\n",
    "    sorted_scores.append(df)\n",
    "\n",
    "# Concatenate all sorted DataFrames into a single DataFrame\n",
    "sorted_scores = pd.concat(sorted_scores)\n",
    "\n",
    "# save scores\n",
    "sorted_scores.to_csv(modeling_dir / \"coeff_scores_per_injury.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metadata-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
